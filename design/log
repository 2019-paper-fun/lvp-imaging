Day 1
=====

Discussion:
-> General introduction, eye stuff, slit lamp
-> Denoising, illumination correction for raw images

Work:
-> Familiarised with the lab
-> Got hold of the camera being used, tested resolution and noise variance

Issues and Todos for tomorrow and later:
-> Understand what the method does and the reflective case						| ?? 																
-> LED Matrix, decide what to do for "low illumination by LEDs at edges"				| Done.
-> Test-bench: Mostly transparency, no reflection effects on our measurement				| Done.
-> 3D print something for the camera									| Done.
-> Play around with lens, camera. See how imaging works. Remember the scale markings on your pad	| Done.
-> Present your approach										| Done.

Notes:
-> Long-term goals, according to me:
	-- Computation acceleration, GPU Parallelization in Matlab (doesn't take much time)
	-- How much redundancy? Convergence speed and LED separation
	-- Deconvolute image using lens PSF, not a low-pass filter

#**************************************************************************************************************

Day 2
=====

Work:
-> Started coding the basic FPM system specified in the paper
-> Finalized the presentation

#**************************************************************************************************************

Day 3
=====

Work:
-> Finished coding the FPM system specified in the paper

#**************************************************************************************************************

Day 4
=====

Discussion:
-> Setting up the system for imaging
-> Optical fibers for light transport?
-> Selecting lenses for two-lens system (50mm and 50mm)
-> Familiarised with the optical table and other systems in the lab

#**************************************************************************************************************

Day 5
=====

Work:
-> 3D-printing slide holder and holders for the lens system
-> Aligning lenses and source with the laser

#**************************************************************************************************************

Day 6
=====

Work:
-> Re-designing the slide holder and 3D-printing it
-> Tried to image slide sample with the LED source in lab, ended up imaging diffraction patterns
-> Diffuse source needed to prevent saturation
-> Took pictures of the slide under a microscope

#**************************************************************************************************************

Day 7
=====

Work:
-> Found the LED array and made it work
-> Changed imaging lens to 150mm focal length, 3x magnification
-> Focussed the sample on the camera feed
-> Remove dust particles by blowing on the CCD and the lenses!
-> Aligned the LED array source to center it and illuminate the entire FOV properly
-> Increase LED intensity?
-> 3D-printing a holder for the LED array
-> Decided that the test sample would be a transparency because slides are thick and we're not sure where we're
   focussing if we try to use a slide

#**************************************************************************************************************

Day 8
=====

Work:
-> Finished setting up the system
-> Camera fixed, both lenses fixed, slide on X stage and LED array source on magnetic mount
-> Adjust camera contrast, exposure, FPS to get a good image
-> Aligned the LED array source to center it and illuminate the entire FOV properly
-> Removed reflection artefacts from the FOV by attaching a paper pipe between the lenses
-> Improved focus with the LED array using the center LEDs
-> Imaged the sample illuminating different LEDs. Find images in images/20141129_Transparency
-> Naming convention is yyyymmdd_Transparency_xy.png. Top left looking from the sample is 11. X increases to
   the right, Y increases towards the bottom
-> Distance between the LED matrix surface and the transparency was 21.9cm
-> OK if LED intensity is unchanged
-> Working on the mathematics behind the method and processing the images

Questions and insights:
-> Should the image shift with LEDs? It will shift a bit because incident light direction is changing, that's
   okay
-> Illumination from a corner will give sharper images as the corners/boundaries shall gain prominence (we are
   looking at their projections). We also do not want to lose any phase information as this is essential to do
   an ifft. The shift in illumination direction wavevector shall introduce a term of the form exp(jwt) which
   shall introduce the shift in the fourier domain. THis hypothesis is subject to rigorous mathematical
   verification, which we shall be doing.
-> We observed that changing the FPS on the camera software changed the contrast - why?
